{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSIIb6ey0POS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deeplake==3.9.27\n",
            "  Using cached deeplake-3.9.27-py3-none-any.whl\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting openai\n",
            "  Using cached openai-1.105.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken\n",
            "  Using cached tiktoken-0.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting llama-index\n",
            "  Using cached llama_index-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting cohere\n",
            "  Using cached cohere-5.17.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting numpy<2.0 (from deeplake==3.9.27)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
            "Collecting pillow~=10.4.0 (from deeplake==3.9.27)\n",
            "  Using cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
            "Collecting boto3 (from deeplake==3.9.27)\n",
            "  Using cached boto3-1.40.23-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting click (from deeplake==3.9.27)\n",
            "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pathos (from deeplake==3.9.27)\n",
            "  Using cached pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting humbug>=0.3.1 (from deeplake==3.9.27)\n",
            "  Using cached humbug-0.3.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting tqdm (from deeplake==3.9.27)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting lz4 (from deeplake==3.9.27)\n",
            "  Using cached lz4-4.4.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting pyjwt (from deeplake==3.9.27)\n",
            "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting aioboto3>=10.4.0 (from deeplake==3.9.27)\n",
            "  Using cached aioboto3-15.1.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: nest_asyncio in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake==3.9.27) (1.6.0)\n",
            "Collecting pydantic (from deeplake==3.9.27)\n",
            "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langsmith>=0.1.17 (from langchain)\n",
            "  Using cached langsmith-0.4.23-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Using cached sqlalchemy-2.0.43-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Using cached jiter-0.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting typing-extensions<5,>=4.11 (from openai)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken)\n",
            "  Using cached regex-2025.9.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Using cached llama_index_cli-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.4 (from llama-index)\n",
            "  Using cached llama_index_core-0.13.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Using cached llama_index_embeddings_openai-0.5.0-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Using cached llama_index_indices_managed_llama_cloud-0.9.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Using cached llama_index_llms_openai-0.5.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Using cached llama_index_readers_file-0.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Using cached llama_index_readers_llama_parse-0.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index)\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Using cached fastavro-1.12.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (5.7 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
            "  Using cached pydantic_core-2.39.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
            "Collecting tokenizers<1,>=0.15 (from cohere)\n",
            "  Using cached tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Using cached types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting aiobotocore==2.24.0 (from aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached aiobotocore-2.24.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting aiofiles>=23.2.1 (from aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.9.2 (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.39.12,>=1.39.9 (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached botocore-1.39.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27) (2.9.0.post0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
            "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
            "Collecting boto3 (from deeplake==3.9.27)\n",
            "  Using cached boto3-1.39.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->deeplake==3.9.27)\n",
            "  Using cached s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging>=23.2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
            "  Using cached orjson-3.11.3-cp312-cp312-macosx_15_0_arm64.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
            "  Using cached zstandard-0.24.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
            "Collecting aiosqlite (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fsspec>=2023.5.0 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached llama_index_workflows-1.3.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting networkx>=3.0 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: platformdirs in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.4->llama-index) (4.4.0)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached beautifulsoup4-4.13.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pandas<2.3.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
            "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting joblib (from nltk>3.8.1->llama-index)\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic->deeplake==3.9.27)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
            "  Using cached pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic->deeplake==3.9.27)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
            "  Using cached charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (36 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<1,>=0.15->cohere)\n",
            "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ppft>=1.7.7 (from pathos->deeplake==3.9.27)\n",
            "  Using cached ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.4.0 (from pathos->deeplake==3.9.27)\n",
            "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.6 (from pathos->deeplake==3.9.27)\n",
            "  Using cached pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.18 (from pathos->deeplake==3.9.27)\n",
            "  Using cached multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27)\n",
            "  Using cached yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (73 kB)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached griffe-1.13.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere)\n",
            "  Using cached hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached llama_index_instrumentation-0.4.0-py3-none-any.whl.metadata (252 bytes)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached greenlet-3.2.4-cp312-cp312-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Using cached llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Using cached llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv<2,>=1.0.1 (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake==3.9.27) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.4->llama-index)\n",
            "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
            "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "Using cached openai-1.105.0-py3-none-any.whl (928 kB)\n",
            "Using cached tiktoken-0.11.0-cp312-cp312-macosx_11_0_arm64.whl (996 kB)\n",
            "Using cached llama_index-0.13.4-py3-none-any.whl (7.0 kB)\n",
            "Using cached cohere-5.17.0-py3-none-any.whl (295 kB)\n",
            "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Using cached aioboto3-15.1.0-py3-none-any.whl (35 kB)\n",
            "Using cached aiobotocore-2.24.0-py3-none-any.whl (84 kB)\n",
            "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
            "Using cached boto3-1.39.11-py3-none-any.whl (139 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached fastavro-1.12.0-cp312-cp312-macosx_10_13_universal2.whl (944 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached humbug-0.3.2-py3-none-any.whl (15 kB)\n",
            "Using cached jiter-0.10.0-cp312-cp312-macosx_11_0_arm64.whl (320 kB)\n",
            "Using cached langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
            "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
            "Using cached langsmith-0.4.23-py3-none-any.whl (378 kB)\n",
            "Using cached llama_index_cli-0.5.0-py3-none-any.whl (28 kB)\n",
            "Using cached llama_index_core-0.13.4-py3-none-any.whl (7.6 MB)\n",
            "Using cached llama_index_embeddings_openai-0.5.0-py3-none-any.whl (7.0 kB)\n",
            "Using cached llama_index_indices_managed_llama_cloud-0.9.3-py3-none-any.whl (17 kB)\n",
            "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Using cached llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "Using cached llama_index_llms_openai-0.5.4-py3-none-any.whl (25 kB)\n",
            "Using cached llama_index_readers_file-0.5.2-py3-none-any.whl (51 kB)\n",
            "Using cached llama_index_readers_llama_parse-0.5.0-py3-none-any.whl (3.2 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
            "Using cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
            "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
            "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "Using cached regex-2025.9.1-cp312-cp312-macosx_11_0_arm64.whl (287 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached sqlalchemy-2.0.43-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
            "Using cached tokenizers-0.22.0-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Using cached lz4-4.4.4-cp312-cp312-macosx_11_0_arm64.whl (189 kB)\n",
            "Using cached pathos-0.3.4-py3-none-any.whl (82 kB)\n",
            "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Using cached aiohttp-3.12.15-cp312-cp312-macosx_11_0_arm64.whl (469 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Using cached beautifulsoup4-4.13.5-py3-none-any.whl (105 kB)\n",
            "Using cached botocore-1.39.11-py3-none-any.whl (13.9 MB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl (205 kB)\n",
            "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached llama_index_workflows-1.3.0-py3-none-any.whl (42 kB)\n",
            "Using cached llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Using cached llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "Using cached multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached orjson-3.11.3-cp312-cp312-macosx_15_0_arm64.whl (127 kB)\n",
            "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
            "Using cached pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Using cached ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "Using cached pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl (39 kB)\n",
            "Using cached zstandard-0.24.0-cp312-cp312-macosx_11_0_arm64.whl (640 kB)\n",
            "Using cached aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.7.0-cp312-cp312-macosx_11_0_arm64.whl (46 kB)\n",
            "Using cached greenlet-3.2.4-cp312-cp312-macosx_11_0_universal2.whl (274 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached llama_index_instrumentation-0.4.0-py3-none-any.whl (14 kB)\n",
            "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Using cached multidict-6.6.4-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
            "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Using cached propcache-0.3.2-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached yarl-1.20.1-cp312-cp312-macosx_11_0_arm64.whl (89 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Using cached griffe-1.13.0-py3-none-any.whl (139 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
            "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, pytz, filetype, dirtyjson, zstandard, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, soupsieve, sniffio, setuptools, regex, PyYAML, python-dotenv, pypdf, pyjwt, propcache, ppft, pox, pillow, orjson, numpy, networkx, mypy-extensions, multidict, marshmallow, MarkupSafe, lz4, jsonpointer, joblib, jmespath, jiter, idna, httpx-sse, hf-xet, h11, greenlet, fsspec, frozenlist, filelock, fastavro, distro, dill, defusedxml, colorama, click, charset_normalizer, certifi, attrs, annotated-types, aioitertools, aiohappyeyeballs, aiofiles, yarl, typing-inspection, typing-inspect, types-requests, SQLAlchemy, requests, pydantic-core, pandas, nltk, multiprocess, jsonpatch, jinja2, httpcore, griffe, deprecated, botocore, beautifulsoup4, anyio, aiosqlite, aiosignal, tiktoken, s3transfer, requests-toolbelt, pydantic, pathos, humbug, huggingface-hub, httpx, dataclasses-json, aiohttp, tokenizers, openai, llama-index-instrumentation, llama-cloud, langsmith, boto3, banks, aiobotocore, llama-index-workflows, langchain-core, cohere, llama-index-core, langchain-text-splitters, aioboto3, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, langchain, deeplake, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
            "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 SQLAlchemy-2.0.43 aioboto3-15.1.0 aiobotocore-2.24.0 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 aiosqlite-0.21.0 annotated-types-0.7.0 anyio-4.10.0 attrs-25.3.0 banks-2.2.0 beautifulsoup4-4.13.5 boto3-1.39.11 botocore-1.39.11 certifi-2025.8.3 charset_normalizer-3.4.3 click-8.2.1 cohere-5.17.0 colorama-0.4.6 dataclasses-json-0.6.7 deeplake-3.9.27 defusedxml-0.7.1 deprecated-1.2.18 dill-0.4.0 dirtyjson-1.0.8 distro-1.9.0 fastavro-1.12.0 filelock-3.19.1 filetype-1.2.0 frozenlist-1.7.0 fsspec-2025.9.0 greenlet-3.2.4 griffe-1.13.0 h11-0.16.0 hf-xet-1.1.9 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 huggingface-hub-0.34.4 humbug-0.3.2 idna-3.10 jinja2-3.1.6 jiter-0.10.0 jmespath-1.0.1 joblib-1.5.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.75 langchain-text-splitters-0.3.11 langsmith-0.4.23 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.13.4 llama-index-cli-0.5.0 llama-index-core-0.13.4 llama-index-embeddings-openai-0.5.0 llama-index-indices-managed-llama-cloud-0.9.3 llama-index-instrumentation-0.4.0 llama-index-llms-openai-0.5.4 llama-index-readers-file-0.5.2 llama-index-readers-llama-parse-0.5.0 llama-index-workflows-1.3.0 llama-parse-0.6.54 lz4-4.4.4 marshmallow-3.26.1 multidict-6.6.4 multiprocess-0.70.18 mypy-extensions-1.1.0 networkx-3.5 nltk-3.9.1 numpy-1.26.4 openai-1.105.0 orjson-3.11.3 pandas-2.2.3 pathos-0.3.4 pillow-10.4.0 pox-0.3.6 ppft-1.7.7 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pyjwt-2.10.1 pypdf-6.0.0 python-dotenv-1.1.1 pytz-2025.2 regex-2025.9.1 requests-2.32.5 requests-toolbelt-1.0.0 s3transfer-0.13.1 setuptools-80.9.0 sniffio-1.3.1 soupsieve-2.8 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.11.0 tokenizers-0.22.0 tqdm-4.67.1 types-requests-2.32.4.20250809 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 wrapt-1.17.3 yarl-1.20.1 zstandard-0.24.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting llama-index-vector-stores-deeplake\n",
            "  Using cached llama_index_vector_stores_deeplake-0.4.0-py3-none-any.whl.metadata (446 bytes)\n",
            "Requirement already satisfied: deeplake>=3.9.12 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-vector-stores-deeplake) (3.9.27)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-vector-stores-deeplake) (0.13.4)\n",
            "Requirement already satisfied: pyjwt in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-vector-stores-deeplake) (2.10.1)\n",
            "Requirement already satisfied: numpy<2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (10.4.0)\n",
            "Requirement already satisfied: boto3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.39.11)\n",
            "Requirement already satisfied: click in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (8.2.1)\n",
            "Requirement already satisfied: pathos in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.3.4)\n",
            "Requirement already satisfied: humbug>=0.3.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.3.2)\n",
            "Requirement already satisfied: tqdm in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (4.67.1)\n",
            "Requirement already satisfied: lz4 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (4.4.4)\n",
            "Requirement already satisfied: aioboto3>=10.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (15.1.0)\n",
            "Requirement already satisfied: nest_asyncio in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.6.0)\n",
            "Requirement already satisfied: pydantic in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (2.11.7)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2025.9.0)\n",
            "Requirement already satisfied: httpx in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.3.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.9.1)\n",
            "Requirement already satisfied: platformdirs in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.17.3)\n",
            "Requirement already satisfied: aiobotocore==2.24.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (2.24.0)\n",
            "Requirement already satisfied: aiofiles>=23.2.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (24.1.0)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.12.0)\n",
            "Requirement already satisfied: botocore<1.39.12,>=1.39.9 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.39.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (2.9.0.post0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.0.1)\n",
            "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (6.6.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.20.1)\n",
            "Requirement already satisfied: griffe in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.1.6)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from boto3->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.13.1)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.4.0)\n",
            "Requirement already satisfied: joblib in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2025.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.26.1)\n",
            "Requirement already satisfied: anyio in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.16.0)\n",
            "Requirement already satisfied: ppft>=1.7.7 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.7.7)\n",
            "Requirement already satisfied: dill>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.4.0)\n",
            "Requirement already satisfied: pox>=0.3.6 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.3.6)\n",
            "Requirement already satisfied: multiprocess>=0.70.18 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pathos->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.70.18)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore==2.24.0->aiobotocore[boto3]==2.24.0->aioboto3>=10.4.0->deeplake>=3.9.12->llama-index-vector-stores-deeplake) (1.17.0)\n",
            "Using cached llama_index_vector_stores_deeplake-0.4.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: llama-index-vector-stores-deeplake\n",
            "Successfully installed llama-index-vector-stores-deeplake-0.4.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index-llms-openai in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (0.5.4)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-llms-openai) (0.13.4)\n",
            "Requirement already satisfied: openai<2,>=1.81.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-llms-openai) (1.105.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2025.9.0)\n",
            "Requirement already satisfied: httpx in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (10.4.0)\n",
            "Requirement already satisfied: platformdirs in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (4.4.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.17.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2,>=1.81.0->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: griffe in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.1.6)\n",
            "Requirement already satisfied: certifi in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.4.0)\n",
            "Requirement already satisfied: click in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (8.2.1)\n",
            "Requirement already satisfied: joblib in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2025.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-openai) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install deeplake==3.9.27 langchain openai tiktoken llama-index cohere llama-index-postprocessor-cohere-rerank\n",
        "%pip install llama-index-vector-stores-deeplake\n",
        "%pip install llama-index-llms-openai llama-index-question-gen-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ul1SFfON0TD1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv(\"../.env\")\n",
        "assert os.getenv(\"OPENAI_API_KEY\")\n",
        "assert os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "assert os.getenv(\"COHERE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7rXjNi00bWW",
        "outputId": "d9e073ef-a76d-4977-c1e9-1afb3199d4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 75042  100 75042    0     0   546k      0 --:--:-- --:--:-- --:--:--  546k\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p \"data/paul_graham/\"\n",
        "!curl \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\" -o \"data/paul_graham/paul_graham_essay.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C1Q0cMtj0kOs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\n",
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h9CPwNm10vj2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43\n",
            "Node ID: cc36dd9d-b650-4649-b573-1bccd1af4e8b\n",
            "Text: What I Worked On  February 2021  Before college the two main\n",
            "things I worked on, outside of school, were writing and programming. I\n",
            "didn't write essays. I wrote what beginning writers were supposed to\n",
            "write then, and probably still are: short stories. My stories were\n",
            "awful. They had hardly any plot, just characters with strong feelings,\n",
            "which I ...\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "\n",
        "\n",
        "# chunc documents and create nodes\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=64)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "print(len(nodes))\n",
        "print(nodes[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96K3MP511gh7",
        "outputId": "e0d44a22-f87f-4a99-e766-a0675cc2f22d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages/humbug/report.py:47: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources  # type: ignore\n",
            "/Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.3.1) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep Lake Dataset in hub://yaroslava/LlamaIndex_paulgraham_essay already exists, loading from the storage\n"
          ]
        }
      ],
      "source": [
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "\n",
        "\n",
        "my_activeloop_org_id = \"yaroslava\"\n",
        "my_activeloop_dataset_name = \"LlamaIndex_paulgraham_essay\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "# Create an index over the documnts\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FaH-fN_b1PQo"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext\n",
        "\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "storage_context.docstore.add_documents(nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBGiu_3j17mX",
        "outputId": "eb0a8684-63c9-4190-8388-9304abc12768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:48:32,905 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading data to deeplake dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:02<00:00, 20.03it/s]\n",
            "\\"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset(path='hub://yaroslava/LlamaIndex_paulgraham_essay', tensors=['embedding', 'id', 'metadata', 'text'])\n",
            "\n",
            "  tensor      htype      shape      dtype  compression\n",
            "  -------    -------    -------    -------  ------- \n",
            " embedding  embedding  (86, 1536)  float32   None   \n",
            "    id        text      (86, 1)      str     None   \n",
            " metadata     json      (86, 1)      str     None   \n",
            "   text       text      (86, 1)      str     None   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " \r"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uOoF3OYa2a-q"
      },
      "outputs": [],
      "source": [
        "query_engine = vector_index.as_query_engine(streaming=True, similarity_top_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpbkU6GR2mUC",
        "outputId": "515e4b9f-9508-41c1-ff75-52a9b6d9c0c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:49:25,401 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 14:49:27,659 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paul Graham organizes a summer program called the Summer Founders Program where undergraduates start startups instead of taking temporary jobs at tech companies during the summer. He also gives talks on startups and seed funding, and eventually starts an investment firm with partners."
          ]
        }
      ],
      "source": [
        "streaming_response = query_engine.query(\n",
        "    \"What does Paul Graham do?\",\n",
        ")\n",
        "streaming_response.print_response_stream()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l7VRFwBL3oS"
      },
      "source": [
        "# SubQuestion Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "semCwp2XMmXq"
      },
      "outputs": [],
      "source": [
        "query_engine = vector_index.as_query_engine(similarity_top_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UYfJFCaGL3B_"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "\n",
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=query_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"pg_essay\",\n",
        "            description=\"Paul Graham essay on What I Worked On\",\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    query_engine_tools=query_engine_tools,\n",
        "    use_async=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDRMYb9HMH7a",
        "outputId": "7e4eadba-7868-4927-b6a3-cc336f99b058"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:52:23,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 14:52:23,176 - INFO - Retrying request to /embeddings in 0.459244 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 3 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What did Paul Graham work on before Y Combinator?\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] Q: What did Paul Graham work on during Y Combinator?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] Q: What did Paul Graham work on after Y Combinator?\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:52:23,479 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 14:52:23,516 - INFO - Retrying request to /chat/completions in 0.455333 seconds\n",
            "2025-09-04 14:52:23,886 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 14:52:23,913 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 14:52:24,748 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;2;90;149;237m[pg_essay] A: During Y Combinator, Paul Graham worked on writing essays, working on YC, and developing a new version of Arc.\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:52:25,117 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;2;237;90;200m[pg_essay] A: Before Y Combinator, Paul Graham worked on a new version of Arc in the summer of 2006. This version of Arc was compiled into Scheme, and to test it, he wrote Hacker News. Initially, Hacker News was meant to be a news aggregator for startup founders called Startup News, but it was later changed to Hacker News with a broader topic to engage intellectual curiosity.\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:52:27,062 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;2;11;159;203m[pg_essay] A: After Y Combinator, Paul Graham worked on a new version of Arc in the summer of 2006. This version of Arc was compiled into Scheme. To test this new Arc, he created Hacker News, which was originally intended to be a news aggregator for startup founders. However, he later changed the name to Hacker News and broadened the topic to engage intellectual curiosity beyond just startups.\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 14:52:29,007 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"How was Paul Grahams life different before, during, and after YC?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRvnUf7zMLBF",
        "outputId": "4f726217-13b5-4fb6-ee60-741f29358fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> The final response:\n",
            " Paul Graham's focus before Y Combinator was on developing a new version of Arc and creating Hacker News to test it. During his time at Y Combinator, he worked on writing essays, YC operations, and further developing Arc. After Y Combinator, he continued working on a new version of Arc and the creation of Hacker News, which transitioned from a startup-focused news aggregator to a platform with broader intellectual topics.\n"
          ]
        }
      ],
      "source": [
        "print( \">>> The final response:\\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8jeNI3Igwqv"
      },
      "source": [
        "# Cohere Rerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVJOtIHQgxlf"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "\n",
        "# Get your cohere API key on: www.cohere.com\n",
        "co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
        "\n",
        "# Example query and passages\n",
        "query = \"What is the capital of the United States?\"\n",
        "documents = [\n",
        "   \"Carson City is the capital city of the American state of Nevada. At the  2010 United States Census, Carson City had a population of 55,274.\",\n",
        "   \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\n",
        "   \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\n",
        "   \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \",\n",
        "   \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
        "   \"North Dakota is a state in the United States. 672,591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\"\n",
        "   ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0nOLQmmg3yY",
        "outputId": "d5269adb-2fc3-4a0e-d977-6e0f44ae0fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document Rank: 1, Document Index: 3\n",
            "Document: Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \n",
            "Relevance Score: 0.98\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 1\n",
            "Document: The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\n",
            "Relevance Score: 0.30\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 4\n",
            "Document: Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\n",
            "Relevance Score: 0.28\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results = co.rerank(query=query, documents=documents, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "\n",
        "for idx, r in enumerate(results):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bifEKCqihBBy"
      },
      "source": [
        "# Cohere in LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AtRoHfgClgqS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
        "\n",
        "\n",
        "\n",
        "cohere_rerank = CohereRerank(api_key=os.environ.get(\"COHERE_API_KEY\"), top_n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qpU4Qwo3lgns"
      },
      "outputs": [],
      "source": [
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=10,\n",
        "    node_postprocessors=[cohere_rerank],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uvVyML8lgkx",
        "outputId": "d29ad8d4-cd75-477c-a0fc-3272d9ff0490"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-04 15:27:29,513 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 15:27:29,920 - INFO - HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
            "2025-09-04 15:27:31,403 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sam Altman was involved in the decision-making process to reorganize Y Combinator (YC) and eventually agreed to become the president of YC starting with the winter 2014 batch.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"What did Sam Altman do in this essay?\",\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDx16J7Flgfa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

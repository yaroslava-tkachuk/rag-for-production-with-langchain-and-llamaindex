{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U114XcpretGB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: deeplake 3.9.52 does not provide the extra 'enterprise'\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet tiktoken langchain-openai python-dotenv datasets langchain beautifulsoup4 html2text ragas \"deeplake[enterprise]<4.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0LOMxQvMe5rp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv(\"../.env\")\n",
        "assert os.getenv(\"OPENAI_API_KEY\")\n",
        "assert os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "assert os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "assert os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
        "assert os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
        "assert os.getenv(\"LANGCHAIN_PROJECT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngpAq3Wse8uw",
        "outputId": "6a2a8a98-b745-4847-c9c0-cd1ce52b5c82"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load docs\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "data = loader.load()\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP6xmZWIgQnX",
        "outputId": "f471c1d9-d5dd-419d-b42d-37d305bbc51b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "len(all_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxq2-2FagVww",
        "outputId": "7cd4ef77-28da-4a4d-8581-2f4186ee8681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.3.1) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
            "  warnings.warn(\n",
            "/var/folders/nl/9vvy243s0cgd8rww2jfgd9jw0000gn/T/ipykernel_3438/4054566647.py:6: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  vectorstore = DeepLake.from_documents(documents=all_splits, dataset_path=\"hub://yaroslava/langsmith_intro\", embedding=OpenAIEmbeddings(), overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Deep Lake dataset has been successfully created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating 133 embeddings in 1 batches of size 133:: 100%|██████████| 1/1 [00:12<00:00, 12.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset(path='hub://yaroslava/langsmith_intro', tensors=['text', 'metadata', 'embedding', 'id'])\n",
            "\n",
            "  tensor      htype       shape      dtype  compression\n",
            "  -------    -------     -------    -------  ------- \n",
            "   text       text      (133, 1)      str     None   \n",
            " metadata     json      (133, 1)      str     None   \n",
            " embedding  embedding  (133, 1536)  float32   None   \n",
            "    id        text      (133, 1)      str     None   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Store splits\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import DeepLake\n",
        "\n",
        "\n",
        "vectorstore = DeepLake.from_documents(documents=all_splits, dataset_path=\"hub://yaroslava/langsmith_intro\", embedding=OpenAIEmbeddings(), overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym9fbSregVup",
        "outputId": "e454c9d0-1e88-4434-cee8-618f011aaa33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RAG prompt\n",
        "from langchain import hub\n",
        "\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt:50442af1\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cP1iwkltgVsD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/nl/9vvy243s0cgd8rww2jfgd9jw0000gn/T/ipykernel_3438/3053291969.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
          ]
        }
      ],
      "source": [
        "# LLM\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pRCwxYzBjKAf"
      },
      "outputs": [],
      "source": [
        "# RetrievalQA\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    chain_type_kwargs={\"prompt\": prompt}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "17Ebw-IRjJ94",
        "outputId": "9c216365-9ce9-44b1-cf2a-258a78186e48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/nl/9vvy243s0cgd8rww2jfgd9jw0000gn/T/ipykernel_3438/1574984886.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": question})\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The approaches to Task Decomposition include using LLM with simple prompting, task-specific instructions, and human inputs. Task decomposition involves breaking down large tasks into smaller subgoals for efficient handling of complex tasks and reflecting on past actions to improve future results. Challenges in long-term planning and task decomposition include adjusting plans in the face of unexpected errors, which LLMs struggle with compared to humans.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"What are the approaches to Task Decomposition?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgfRcsP5h2zj"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12HYhW_fgVkv",
        "outputId": "eab876ca-f8ed-498a-b453-a182ac446f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                  Version\n",
            "------------------------ -----------\n",
            "aioboto3                 15.1.0\n",
            "aiobotocore              2.24.0\n",
            "aiofiles                 24.1.0\n",
            "aiohappyeyeballs         2.6.1\n",
            "aiohttp                  3.12.15\n",
            "aioitertools             0.12.0\n",
            "aiosignal                1.4.0\n",
            "annotated-types          0.7.0\n",
            "anyio                    4.10.0\n",
            "appdirs                  1.4.4\n",
            "appnope                  0.1.4\n",
            "asttokens                3.0.0\n",
            "attrs                    25.3.0\n",
            "beautifulsoup4           4.13.5\n",
            "boto3                    1.39.11\n",
            "botocore                 1.39.11\n",
            "certifi                  2025.8.3\n",
            "charset-normalizer       3.4.3\n",
            "click                    8.2.1\n",
            "comm                     0.2.3\n",
            "dataclasses-json         0.6.7\n",
            "datasets                 4.0.0\n",
            "debugpy                  1.8.16\n",
            "decorator                5.2.1\n",
            "deepframe                0.1.1\n",
            "deeplake                 3.9.52\n",
            "dill                     0.4.0\n",
            "diskcache                5.6.3\n",
            "distro                   1.9.0\n",
            "docstring_parser         0.17.0\n",
            "executing                2.2.1\n",
            "filelock                 3.19.1\n",
            "frozenlist               1.7.0\n",
            "fsspec                   2025.3.0\n",
            "gitdb                    4.0.12\n",
            "GitPython                3.1.45\n",
            "h11                      0.16.0\n",
            "hf-xet                   1.1.9\n",
            "html2text                2025.4.15\n",
            "httpcore                 1.0.9\n",
            "httpx                    0.28.1\n",
            "httpx-sse                0.4.1\n",
            "huggingface-hub          0.34.4\n",
            "humbug                   0.3.2\n",
            "idna                     3.10\n",
            "instructor               1.11.2\n",
            "ipykernel                6.30.1\n",
            "ipython                  9.5.0\n",
            "ipython_pygments_lexers  1.1.1\n",
            "jedi                     0.19.2\n",
            "Jinja2                   3.1.6\n",
            "jiter                    0.10.0\n",
            "jmespath                 1.0.1\n",
            "jsonpatch                1.33\n",
            "jsonpointer              3.0.0\n",
            "jupyter_client           8.6.3\n",
            "jupyter_core             5.8.1\n",
            "langchain                0.3.27\n",
            "langchain-community      0.3.29\n",
            "langchain-core           0.3.75\n",
            "langchain-openai         0.3.32\n",
            "langchain-text-splitters 0.3.11\n",
            "langsmith                0.4.26\n",
            "lz4                      4.4.4\n",
            "markdown-it-py           4.0.0\n",
            "MarkupSafe               3.0.2\n",
            "marshmallow              3.26.1\n",
            "matplotlib-inline        0.1.7\n",
            "mdurl                    0.1.2\n",
            "multidict                6.6.4\n",
            "multiprocess             0.70.18\n",
            "mypy_extensions          1.1.0\n",
            "nest-asyncio             1.6.0\n",
            "numpy                    2.3.2\n",
            "openai                   1.106.1\n",
            "orjson                   3.11.3\n",
            "packaging                25.0\n",
            "pandas                   2.3.2\n",
            "parso                    0.8.5\n",
            "pathos                   0.3.4\n",
            "pexpect                  4.9.0\n",
            "pillow                   10.4.0\n",
            "pip                      24.0\n",
            "platformdirs             4.4.0\n",
            "pox                      0.3.6\n",
            "ppft                     1.7.7\n",
            "prompt_toolkit           3.0.52\n",
            "propcache                0.3.2\n",
            "psutil                   7.0.0\n",
            "ptyprocess               0.7.0\n",
            "pure_eval                0.2.3\n",
            "pyarrow                  21.0.0\n",
            "pydantic                 2.11.7\n",
            "pydantic_core            2.33.2\n",
            "pydantic-settings        2.10.1\n",
            "Pygments                 2.19.2\n",
            "PyJWT                    2.10.1\n",
            "python-dateutil          2.9.0.post0\n",
            "python-dotenv            1.1.1\n",
            "pytz                     2025.2\n",
            "PyYAML                   6.0.2\n",
            "pyzmq                    27.0.2\n",
            "ragas                    0.3.3\n",
            "regex                    2025.9.1\n",
            "requests                 2.32.5\n",
            "requests-toolbelt        1.0.0\n",
            "rich                     14.1.0\n",
            "s3transfer               0.13.1\n",
            "shellingham              1.5.4\n",
            "six                      1.16.0\n",
            "smmap                    5.0.2\n",
            "sniffio                  1.3.1\n",
            "soupsieve                2.8\n",
            "SQLAlchemy               2.0.43\n",
            "stack-data               0.6.3\n",
            "tenacity                 9.1.2\n",
            "tiktoken                 0.11.0\n",
            "tornado                  6.5.2\n",
            "tqdm                     4.67.1\n",
            "traitlets                5.14.3\n",
            "typer                    0.17.4\n",
            "typing_extensions        4.15.0\n",
            "typing-inspect           0.9.0\n",
            "typing-inspection        0.4.1\n",
            "tzdata                   2025.2\n",
            "urllib3                  2.5.0\n",
            "wcwidth                  0.2.13\n",
            "wrapt                    1.17.3\n",
            "xxhash                   3.5.0\n",
            "yarl                     1.20.1\n",
            "zstandard                0.24.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AgfRcsP5h2zj"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

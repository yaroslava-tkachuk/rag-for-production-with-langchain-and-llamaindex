{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-deeplake\n",
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\")\n",
    "assert os.getenv(\"ACTIVELOOP_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install deeplake beautifulsoup4 html2text tiktoken openai llama-index python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89573c53",
   "metadata": {},
   "source": [
    "## 1. Dataset Creation and ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f38081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "def get_all_links(url: str) -> list[str]:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page: {url}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Finding all 'a' tags which typically contain href attribute for links\n",
    "    links = [\n",
    "        urljoin(url, a[\"href\"])\n",
    "        for a in soup.find_all(\"a\", href=True)\n",
    "        if a[\"href\"]\n",
    "    ]\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c90cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "def load_documents(url: str) -> list[Document]:\n",
    "    all_links = get_all_links(url)\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (compatible; MyBot/1.0; +http://example.com/bot)\"\n",
    "    }\n",
    "    loader = AsyncHtmlLoader(all_links, header_template=headers)\n",
    "    docs = loader.load()\n",
    "\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    docs = [Document.from_langchain_format(doc) for doc in docs_transformed]\n",
    "    return docs\n",
    "\n",
    "\n",
    "docs = load_documents(\"https://docs.deeplake.ai/4.3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93479626",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90732671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.evaluation import generate_question_context_pairs\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "vector_store = DeepLakeVectorStore(\n",
    "    dataset_path=\"hub://yaroslava/deeplake_docs_deepmemory2\",\n",
    "    overwrite=True,\n",
    "    runtime={\"tensor_db\": True},\n",
    "    token=os.getenv(\"ACTIVELOOP_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import Node\n",
    "\n",
    "\n",
    "def create_modules(\n",
    "    vector_store: DeepLakeVectorStore,\n",
    "    docs: list[Document] = [],\n",
    "    populate_vector_store: bool =True\n",
    ") -> tuple[StorageContext, list[Node], OpenAI]:\n",
    "    if populate_vector_store:\n",
    "        node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "        nodes = node_parser.get_nodes_from_documents(docs)\n",
    "    else:\n",
    "        nodes = []\n",
    "\n",
    "    # by default, the node ids are set to random uuids. To ensure same id's per run, we manually set them.\n",
    "    for idx, node in enumerate(nodes):\n",
    "        node.id_ = f\"node_{idx}\"\n",
    "\n",
    "    llm = OpenAI(model=\"gpt-4\")\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    return storage_context, nodes, llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context, nodes, llm = create_modules(\n",
    "    docs=docs,\n",
    "    vector_store=vector_store,\n",
    "    # populate_vector_store=False, # uncomment this line to skip populating the vector store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "deep_memory_retriever = vector_index.as_retriever(\n",
    "    similarity_top_k=4, deep_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b474e4d",
   "metadata": {},
   "source": [
    "## 2. Training Deep Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93aeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "import random\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def create_train_test_datasets(\n",
    "    number_of_samples: int = 600, llm: Optional[OpenAI] = None, nodes: Optional[list[Node]] = None, save: bool = False\n",
    ") -> tuple[EmbeddingQAFinetuneDataset, EmbeddingQAFinetuneDataset]:\n",
    "    random_indices = random.sample(range(len(nodes)), number_of_samples)\n",
    "\n",
    "    ratio = int(len(random_indices) * 0.8)\n",
    "\n",
    "    train_indices = random_indices[:ratio]\n",
    "    test_indices = random_indices[ratio:]\n",
    "\n",
    "    train_nodes = [nodes[i] for i in train_indices]\n",
    "    test_nodes = [nodes[i] for i in test_indices]\n",
    "\n",
    "    train_qa_dataset = generate_question_context_pairs(\n",
    "        train_nodes, llm=llm, num_questions_per_chunk=1\n",
    "    )\n",
    "\n",
    "    test_qa_dataset = generate_question_context_pairs(\n",
    "        test_nodes, llm=llm, num_questions_per_chunk=1\n",
    "    )\n",
    "\n",
    "    # [optional] save\n",
    "    if save:\n",
    "        train_qa_dataset.save_json(\n",
    "            f\"deeplake_docs_{number_of_samples}_train.json\"\n",
    "        )\n",
    "        test_qa_dataset.save_json(\n",
    "            f\"deeplake_docs_{number_of_samples}_test.json\"\n",
    "        )\n",
    "    return train_qa_dataset, test_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30984a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa_dataset, test_qa_dataset = create_train_test_datasets(\n",
    "    number_of_samples=600, llm=llm, nodes=nodes, save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa_dataset = EmbeddingQAFinetuneDataset.from_json(\n",
    "    \"deeplake_docs_600_train.json\"\n",
    ")\n",
    "test_qa_dataset = EmbeddingQAFinetuneDataset.from_json(\n",
    "    \"deeplake_docs_600_test.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8155cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_relevance(qa_dataset: EmbeddingQAFinetuneDataset) -> tuple[list[str], list[list[tuple[str, int]]]]:\n",
    "    \"\"\"Function for converting llama-index dataset to correct format for deep memory training\"\"\"\n",
    "    queries = [text for _, text in qa_dataset.queries.items()]\n",
    "    relevant_docs = qa_dataset.relevant_docs\n",
    "    relevance = []\n",
    "    for doc in relevant_docs:\n",
    "        relevance.append([(relevant_docs[doc][0], 1)])\n",
    "    return queries, relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries, train_relevance = create_query_relevance(train_qa_dataset)\n",
    "test_queries, test_relevance = create_query_relevance(test_qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5809cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_relevance[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_relevance[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f478b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "job_id = vector_store.vectorstore.deep_memory.train(\n",
    "    queries=train_queries,\n",
    "    relevance=train_relevance,\n",
    "    embedding_function=embeddings.embed_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ab92f",
   "metadata": {},
   "source": [
    "## 3. DeepMemory Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7aa6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = vector_store.vectorstore.deep_memory.evaluate(\n",
    "    queries=test_queries,\n",
    "    relevance=test_relevance,\n",
    "    embedding_function=embeddings.embed_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def display_results(eval_results: dict[str, list[Any]]) -> pd.DataFrame:\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "    hit_rates = []\n",
    "    mrrs = []\n",
    "    names = []\n",
    "    for name, eval_result in eval_results.items():\n",
    "        metric_dicts = []\n",
    "        for er in eval_result:\n",
    "            metric_dict = er.metric_vals_dict\n",
    "            metric_dicts.append(metric_dict)\n",
    "\n",
    "        full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "        hit_rate = full_df[\"hit_rate\"].mean()\n",
    "        mrr = full_df[\"mrr\"].mean()\n",
    "\n",
    "        hit_rates.append(hit_rate)\n",
    "        mrrs.append(mrr)\n",
    "        names.append(name)\n",
    "\n",
    "    metric_df = pd.DataFrame(\n",
    "        [\n",
    "            {\"retrievers\": names[i], \"hit_rate\": hit_rates[i], \"mrr\": mrrs[i]}\n",
    "            for i in range(2)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "\n",
    "deep_memory_retriever = vector_index.as_retriever(\n",
    "    similarity_top_k=10, vector_store_kwargs={\"deep_memory\": True}\n",
    ")\n",
    "dm_retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=deep_memory_retriever\n",
    ")\n",
    "\n",
    "dm_eval_results = await dm_retriever_evaluator.aevaluate_dataset(\n",
    "    test_qa_dataset, retriever=dm_retriever_evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "\n",
    "naive_retriever = vector_index.as_retriever(similarity_top_k=10)\n",
    "naive_retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=naive_retriever\n",
    ")\n",
    "\n",
    "naive_eval_results = await naive_retriever_evaluator.aevaluate_dataset(\n",
    "    test_qa_dataset, retriever=naive_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {\n",
    "    f\"{mode} with Deep Memory top-10 eval\": eval_result\n",
    "    for mode, eval_result in zip(\n",
    "        [\"with\", \"without\"], [dm_eval_results, naive_eval_results]\n",
    "    )\n",
    "}\n",
    "\n",
    "display_results(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a559ee",
   "metadata": {},
   "source": [
    "## 4. Deep Memory Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(\n",
    "    vector_store_kwargs={\"deep_memory\": True}, llm=llm\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"How can you connect your own storage to the deeplake?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    vector_store_kwargs={\"deep_memory\": False}, llm=llm\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"How can you connect your own storage to the deeplake?\"\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

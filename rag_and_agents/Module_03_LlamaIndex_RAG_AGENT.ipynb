{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oLsz4honE_jq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-agent-openai 0.4.12 requires llama-index-core<0.13,>=0.12.41, but you have llama-index-core 0.13.5 which is incompatible.\n",
            "llama-index-agent-openai 0.4.12 requires llama-index-llms-openai<0.5,>=0.4.0, but you have llama-index-llms-openai 0.5.4 which is incompatible.\n",
            "llama-index-agent-openai-legacy 0.3.4 requires llama-index-core<0.13,>=0.12.41, but you have llama-index-core 0.13.5 which is incompatible.\n",
            "llama-index-agent-openai-legacy 0.3.4 requires llama-index-llms-openai<0.5,>=0.4.0, but you have llama-index-llms-openai 0.5.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index-vector-stores-deeplake in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (0.4.0)\n",
            "Requirement already satisfied: llama-index-llms-openai in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (0.5.4)\n",
            "Requirement already satisfied: deeplake>=3.9.12 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-vector-stores-deeplake) (4.3.1)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-vector-stores-deeplake) (0.13.5)\n",
            "Requirement already satisfied: pyjwt in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-vector-stores-deeplake) (2.10.1)\n",
            "Requirement already satisfied: openai<2,>=1.81.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-llms-openai) (1.106.1)\n",
            "Requirement already satisfied: numpy in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (2.3.2)\n",
            "Requirement already satisfied: deepframe in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from deeplake>=3.9.12->llama-index-vector-stores-deeplake) (0.1.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2025.9.0)\n",
            "Requirement already satisfied: httpx in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (4.4.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.17.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2,>=1.81.0->llama-index-llms-openai) (3.10)\n",
            "Requirement already satisfied: griffe in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.1.6)\n",
            "Requirement already satisfied: certifi in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.4.0)\n",
            "Requirement already satisfied: click in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (8.2.1)\n",
            "Requirement already satisfied: joblib in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2025.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-deeplake) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index-agent-openai in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (0.4.12)\n",
            "Requirement already satisfied: llama-index-agent-openai-legacy in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (0.3.4)\n",
            "Collecting llama-index-core<0.13,>=0.12.41 (from llama-index-agent-openai)\n",
            "  Using cached llama_index_core-0.12.52.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index-agent-openai)\n",
            "  Using cached llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: openai>=1.14.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-agent-openai) (1.106.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2025.9.0)\n",
            "Requirement already satisfied: httpx in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.3.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (4.4.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (4.15.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.17.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai) (3.10)\n",
            "Requirement already satisfied: griffe in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.1.6)\n",
            "Requirement already satisfied: certifi in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.4.0)\n",
            "Requirement already satisfied: click in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (8.2.1)\n",
            "Requirement already satisfied: joblib in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2025.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.41->llama-index-agent-openai) (3.0.2)\n",
            "Using cached llama_index_core-0.12.52.post1-py3-none-any.whl (7.6 MB)\n",
            "Using cached llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: llama-index-core, llama-index-llms-openai\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.13.5\n",
            "    Uninstalling llama-index-core-0.13.5:\n",
            "      Successfully uninstalled llama-index-core-0.13.5\n",
            "  Attempting uninstall: llama-index-llms-openai\n",
            "    Found existing installation: llama-index-llms-openai 0.5.4\n",
            "    Uninstalling llama-index-llms-openai-0.5.4:\n",
            "      Successfully uninstalled llama-index-llms-openai-0.5.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-readers-file 0.5.3 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-indices-managed-llama-cloud 0.9.3 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-vector-stores-deeplake 0.4.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index 0.13.5 requires llama-index-core<0.14,>=0.13.5, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index 0.13.5 requires llama-index-llms-openai<0.6,>=0.5.0, but you have llama-index-llms-openai 0.4.7 which is incompatible.\n",
            "llama-index-cli 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-cli 0.5.0 requires llama-index-llms-openai<0.6,>=0.5.0, but you have llama-index-llms-openai 0.4.7 which is incompatible.\n",
            "llama-index-embeddings-openai 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-readers-llama-parse 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llama-index-core-0.12.52.post1 llama-index-llms-openai-0.4.7\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q llama-index deeplake openai cohere dotenv\n",
        "%pip install llama-index-vector-stores-deeplake llama-index-llms-openai\n",
        "%pip install llama-index-agent-openai llama-index-agent-openai-legacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Uh_M0Z0FFJPb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv(\"../.env\")\n",
        "assert os.getenv(\"OPENAI_API_KEY\")\n",
        "assert os.getenv(\"ACTIVELOOP_TOKEN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4xCp6-mN3xw"
      },
      "source": [
        "# Prepare Indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE86KzdvOPgX",
        "outputId": "becf09cb-35a4-4c6c-f26a-6cdb41fbacd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  195k    0  195k    0     0   283k      0 --:--:-- --:--:-- --:--:--  283k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  205k    0  205k    0     0   268k      0 --:--:-- --:--:-- --:--:--  268k\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p \"data/1k/\"\n",
        "!curl \"https://github.com/idontcalculate/data-repo/blob/main/machine_to_end_war.txt\" -o \"data/1k/tesla.txt\"\n",
        "!curl \"https://github.com/idontcalculate/data-repo/blob/main/prodigal_chapter10.txt\" -o \"data/1k/web.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAXcBI5COHWy"
      },
      "source": [
        "### From VectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ufXfJwfcORAa"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "\n",
        "tesla_docs = SimpleDirectoryReader( input_files=[\"data/1k/tesla.txt\"] ).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--NnpT4UOQbv",
        "outputId": "00b40ba0-ae85-412d-c897-8d5ce317b172"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:34:27,828 - WARNING - [S3] Failed to get bucket region for URL: snark-hub/protected/yaroslava/LlamaIndex_tesla_predictions/ with error: [S3] INVALID_ACCESS_KEY_ID snark-hub The AWS Access Key Id you provided does not exist in our records. \n"
          ]
        }
      ],
      "source": [
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "\n",
        "\n",
        "my_activeloop_org_id = \"yaroslava\"\n",
        "my_activeloop_dataset_name = \"LlamaIndex_tesla_predictions\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "# Create an index over the documnts\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "loC5XGShPtf_"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext\n",
        "\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pPld5m3Ptco",
        "outputId": "8b9f21fd-0780-4d61-8a6e-97d524d68232"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:34:41,634 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "\n",
        "tesla_index = VectorStoreIndex.from_documents(tesla_docs, storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIQLCDvuQPPU"
      },
      "source": [
        "## From Local Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7lPWnGE_PtaR"
      },
      "outputs": [],
      "source": [
        "webtext_docs = SimpleDirectoryReader(input_files=[\"data/1k/web.txt\"] ).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1ieq9i8QUa1",
        "outputId": "f9da5d43-fbea-494c-9751-21134dc4156c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading llama_index.core.storage.kvstore.simple_kvstore from data/storage/webtext/docstore.json.\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from data/storage/webtext/index_store.json.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:34:49,074 - INFO - Loading all indices.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded the pre-computed index.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "\n",
        "try:\n",
        "  # Try to load the index if it is already calculated\n",
        "  storage_context = StorageContext.from_defaults( persist_dir=\"data/storage/webtext\" )\n",
        "  webtext_index = load_index_from_storage(storage_context)\n",
        "  print(\"Loaded the pre-computed index.\")\n",
        "except:\n",
        "  # Otherwise, generate the indexes\n",
        "  webtext_index = VectorStoreIndex.from_documents(webtext_docs)\n",
        "  webtext_index.storage_context.persist(persist_dir=\"data/storage/webtext\")\n",
        "  print(\"Generated the index.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF3KH4bHRU9L"
      },
      "source": [
        "# Create Query Enginges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MR4BXAVqQnV8"
      },
      "outputs": [],
      "source": [
        "tesla_engine = tesla_index.as_query_engine(similarity_top_k=3)\n",
        "webtext_engine = webtext_index.as_query_engine(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFbYTky1Rgu0"
      },
      "source": [
        "# Create the Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vMptZI0uPtVU"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "\n",
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=tesla_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"tesla_1k\",\n",
        "            description=(\n",
        "                \"Provides information about Tesla's statements that refers to future times and predictions. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=webtext_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"webtext_1k\",\n",
        "            description=(\n",
        "                \"Provides information about tesla's life and biographical data. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CU3MaJ4Rt4R"
      },
      "source": [
        "# Define the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RdBtZi50PtSe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages/llama_index/agent/openai/base.py:144: DeprecationWarning: Call to deprecated class OpenAIAgent. (OpenAIAgent has been deprecated and is not maintained.\n",
            "\n",
            "`FunctionAgent` is the recommended replacement.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n",
            "/Users/coder/Desktop/dev/rag_for_production_activeloop/rag-for-production-with-langchain-and-llamaindex/.venv/lib/python3.12/site-packages/llama_index/agent/openai/step.py:213: DeprecationWarning: Call to deprecated class OpenAIAgentWorker. (OpenAIAgentWorker has been deprecated and is not maintained.\n",
            "\n",
            "`FunctionAgent` is the recommended replacement.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "\n",
        "\n",
        "agent = OpenAIAgent.from_tools(query_engine_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-0kHgKCRiq0",
        "outputId": "8ab2c744-e818-46ec-be40-da17fb1d11f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What influenced Nikola Tesla to become an inventor?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:02,112 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: webtext_1k with args: {\"input\":\"What influenced Nikola Tesla to become an inventor?\"}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:02,422 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-09-05 16:35:03,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got output: Nikola Tesla was influenced to become an inventor by his interest in the effects of mechanical vibrations and their potential applications.\n",
            "========================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:04,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AgentChatResponse(response='Nikola Tesla was influenced to become an inventor by his interest in the effects of mechanical vibrations and their potential applications.', sources=[ToolOutput(blocks=[TextBlock(block_type='text', text='Nikola Tesla was influenced to become an inventor by his interest in the effects of mechanical vibrations and their potential applications.')], tool_name='webtext_1k', raw_input={'input': 'What influenced Nikola Tesla to become an inventor?'}, raw_output=Response(response='Nikola Tesla was influenced to become an inventor by his interest in the effects of mechanical vibrations and their potential applications.', source_nodes=[NodeWithScore(node=TextNode(id_='757983b3-0b15-4da6-a916-d067e025ffb1', embedding=None, metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='07422d86-a33f-4beb-b46a-d15ec9d29bc2', node_type='4', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='350f6898d24bbe393c5f1a8aec4d7c32a411e69f3093573b9f300d9874fa41fe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20406a92-0af9-4a53-8571-b182ffa7ffed', node_type='1', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='66ad6fbd0a0bfc5f107428036c18b47c1fc135dc6573c45fc919616e797cd084'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d240b337-6f22-4ab6-b161-4d4c4fe42869', node_type='1', metadata={}, hash='bb2bfef0fdb1f32a1efc7da29ed93249c05c7311f4c4d76adaaf85019b71f5f8')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\",\"His system of telegeodynamics, using mechanical vibrations, Tesla declared, would make it possible to determine the physical constant of the\",\"\",\"Earth and to locate ore deposits far beneath the surface. This latter prediction has since been fulfilled, for\",\"many oil fields have been discovered by studying the vibrations reflected from sub-surface strata.\",\"\\\\\"So powerful are the effects of the telegeodynamic oscillator,\\\\\" said Tesla in reviewing the subject in the thirties, \\\\\"that I could now go over to the Empire State Building and reduce it to a tangled mass of wreckage in a very short time. I could accomplish this result with utmost certainty and without any difficulty whatever. I would use a small mechanical vibrating device, an engine so small you could slip it in your pocket. I could attach it to any part of the building, start it in operation, allow it twelve to thirteen minutes to come to full resonance. The building would first respond with gentle tremors, and the vibrations would then become so powerful that the whole structure would go into resonant oscillations of such great amplitude and power that rivets in the steel beams would be loosened and sheared. The other stone coating would be thrown off and then the skeleton steel structure would collapse in all its parts. It would take about 2.5 * horsepower to drive the oscillator to produce this effect.\\\\\"\",\"This figure may have been .25 horsepower.\",\"The notes are old and somewhat indistinct. Memory favors the latter figure.\",\"Tesla developed his inventions to the point at which they were spectacular performers before they were demonstrated to the public.\",\"When presented, the performance always greatly exceeded the promise. This was the case with his first public demonstration of \\\\\"wireless,\\\\\" but he complicated the situation by coupling with his radio invention another new idea... the robot.\",\"\",\"Tesla was patriotic, and was proud of his status, which he had acquired in 1889, as a citizen of the United States. He had offered his invention to the Government as a naval weapon, but at heart he was opposed to war.\",\"\\\\\"You do not see there a wireless torpedo,\\\\\"snapped back Tesla with fire flashing in his eyes, \\\\\"you see there the first of a race of robots, mechanical men which will do the laborious work of the human race.\\\\\"\",\"The \\\\\"race of robots\\\\\" was another of Tesla\\'s original and important contributions to human welfare. It was one of the items of his colossal project for increasing human energy and improving the efficiency of its utilization. He visualized the application of the robot idea to warfare as well as to peaceful pursuits; and out of the broad principles enunciated, he developed and accurate picture of warfare as it is being carried on today with the use of giant machines as weapons... the robots he described.', mimetype='text/plain', start_char_idx=193246, end_char_idx=196081, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8364177457900843), NodeWithScore(node=TextNode(id_='199e5af0-39cc-46d2-b1fe-0094ca795e54', embedding=None, metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='07422d86-a33f-4beb-b46a-d15ec9d29bc2', node_type='4', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='350f6898d24bbe393c5f1a8aec4d7c32a411e69f3093573b9f300d9874fa41fe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f29cc8ea-66a3-4f1e-ad12-8dd937b24466', node_type='1', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='7f4ddebc3c006be13184de666ecea5c96d67d408ac2f27e7c9811bf5a7ba791d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='90f9b9a3-3c65-4f8b-9fa4-2d42db76f8ec', node_type='1', metadata={}, hash='67c534fb0d91627bb021a3dee17f603055084cf979e3202213ea5500ab128d20')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Even when he did not so plan events, they appeared to fashion themselves into spectacular climaxes. In 1896 while his fame was still on the ascendant he planned a nice quiet little vibration experiment in his Houston Street laboratory. Since he had moved into these quarters in 1895, the place had established a reputation for itself because of the peculiar noises and lights that emanated from it at all hours of the day and night, and because it was constantly being visited by the most famous people in the country.\",\"The quiet little vibration experiment produced an earthquake, a real earthquake in which people and buildings and everything in them got a more tremendous shaking than they did in any of the natural earthquakes that have visited the metropolis. In an area of a dozen square city blocks, occupied by hundreds of buildings housing tens of thousands of persons, there was a sudden roaring and shaking, shattering of panes of glass, breaking of steam, gas and water pipes. Pandemonium reigned as small objects danced around rooms, plaster descended from walls and ceilings, and pieces of machinery weighing tons were moved from their bolted anchorages and shifted to awkward spots in factory lofts.\",\"\",\"Sounds like New York City\\'s biggest earthquake.\",\"\",\"\\\\\"It was all caused, quite unexpectedly, by a little piece of apparatus you could slip in your pocket,\\\\\" said Tesla.\",\"The device that precipitated the sudden crisis had been used for a long time by Tesla as a toy to amuse his friends. It was a mechanical oscillator, and was used to produce vibrations. The motor-driven device that the barber straps on his hand to give a patron an \\\\\"electric massage\\\\\" is a descendant of Tesla\\'s mechanical oscillator. There is, of course, nothing electric about an \\\\\"electric massage\\\\\" except the power used to produce vibrations which are transmitted through the barber\\'s fingers to the scalp.\",\"Tesla developed in the early nineties a mechanical-electrical oscillator for the generation of high-frequency alternating currents. The driving engine produced on a shaft simple reciprocating motion that was not changed to rotary motion. Mounted on either end of the shaft was a coil of many turns of wire that moved back and forth with high frequency between the poles of electromagnets, and in this way generated high-frequency alternating currents.\",\"The engine was claimed by Tesla to have a very high efficiency compared to the common type of engine, which changed reciprocating to rotary motion by means of a crank shaft. It had no valves or other moving parts, except the reciprocating piston with its attached shaft and coils, so that mechanical losses were very low. It maintained such an extremely high order of constancy of speed, he stated, that the alternating current generated by the oscillator could be used to drive clocks, without and pendulum or balance-wheel control mechanism, and they would keep time more accurately than the Sun.\",\"This engine may have had industrial possibilities but Tesla was not interested in them. To him it was just a convenient way of producing a high-frequency alternating current constant in frequency and voltage, or mechanical vibrations, it used without the electrical parts. He operated the engine on compressed air and also by steam at 320 pounds and also at 80 pounds pressure.\",\"Page 156Author was well informed...\",\"\",\"\",\"It was a mechanical oscillator\",\"While perfecting this devise, he had opportunity to observe interesting effects produced by vibration. These were objectionable in the engine when it was used as a dynamo, so he adopted suitable measures to eliminate or suppress them. The vibrations as such, however, interested him. Although they were detrimental to the machine, he found their physiological effects were, at times, quite pleasant. Later he built a small mechanical oscillator driven by compressed air which was designed for no other purpose than to produce vibrations. He built a platform insulated from the floor by rubber and cork. He then mounted the oscillator on the under side of the platform. The purpose of the rubber cork under the platform was to keep the vibrations from leaking into the building and thereby reducing the effect on the platform. Visitors found this vibrating platform one of the most interesting of the great array of fascinating and fantastic exhibits with which he dazzled the society folk who flocked to his laboratory.\",\"Great hopes were entertained by Tesla of applying these vibrations for therapeutic and health-improving effects. He had opportunity to observe, through his own experience and that of his employees, that they produced some very definite physiological actions.\",\"Samuel Clemens, better known to the public as \\\\\"Mark Twain\\\\\", and Tesla were close friends. Clemens was a frequent visitor to the Tesla laboratory. Tesla had been playing with his vibratory mechanism for some time, and had learned a good deal about the results that followed from varying doses of vibration, when one evening Clemens dropped in.\",\"Clemens, on learning about the new mechanism, wanted to experience its vitalizing vibrations.', mimetype='text/plain', start_char_idx=173309, end_char_idx=178451, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8239940410684508), NodeWithScore(node=TextNode(id_='58f773d7-512f-4244-ba01-8b95ca2f08f2', embedding=None, metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='07422d86-a33f-4beb-b46a-d15ec9d29bc2', node_type='4', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='350f6898d24bbe393c5f1a8aec4d7c32a411e69f3093573b9f300d9874fa41fe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ff2866f-ccf4-4990-a069-893659344147', node_type='1', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='4ddcc501cf0a83e7d3f3b2a4922efa4fd466472ac143f29e8a7d86cf9ca24ab7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='20406a92-0af9-4a53-8571-b182ffa7ffed', node_type='1', metadata={}, hash='81df36ffcf4635f648faaf93d136808ce4a871b0d42e9fc539a40509aac63994')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\",\"Could they reach Tesla\\'s laboratory in time to stop him? Or would the building tumble down on their heads and everyone in it be buried in the ruins, and probably every building in the neighborhood? Maybe he was making the whole Earth shake in this way! Would this madman be destroying the world? It was destroyed once before by water. Maybe this time it would be destroyed by that agent of the devil that they call electricity!\",\"Just as the cops rushed into Tesla\\'s laboratory to tackle... they knew not what... the vibrations stopped and they beheld a strange sight. They arrived just in time to see the tall gaunt figure of the inventor swing a heavy sledge hammer and shatter a small iron contraption mounted on the post in the middle of the room. Pandemonium gave way to a deep, heavy silence.\",\"Tesla was the first to break the silence. Resting his sledge hammer against the pillar, he turned his tall, lean, coatless figure to the cops. He was always self-possessed, always a commanding presence... an effect that could in no way be attributed to his slender build, but seemed more to emanate from his eyes. Bowing from the waist in his courtly manner, he addressed the policemen, who were too out of breath to speak, and probably overawed into silence by their fantastic experience.\",\"\\\\\"Gentleman,\\\\\" he said, \\\\\"I am sorry, but you are just a trifle too late to witness my experiment. I found it necessary to stop it suddenly and unexpectedly and in and unusual way just as you entered. If you will come around this evening I will have another oscillator attached to this platform and\",\"\",\"each of you can stand on it. You will, I am sure, find it a most interesting and pleasurable experience. Now you must leave, for I have many things to do. Good day gentlemen.\\\\\"\",\"George Scherff, Tesla\\'s secretary, was standing near by when Tesla was so dramatically smashed his earthquake maker. Tesla never told the story beyond this point, and Mr. Scherff declares he does not recall what the response of the cops was. Imagination must furnish the finale to the story.\",\"At the moment, though, Tesla was quite sincere in his attitude. He had no idea of what had happened elsewhere in the neighborhood as a result of his experiment, but the effect on his own laboratory had been sufficiently threatening to cause him to halt is suddenly. When he learned the details, however, he was convinced that he was correct in his belief that the field of mechanical vibrations was rich with opportunities for scientific investigation. We have no records available of any further major experiments with vibration in that laboratory. Perhaps the Police and Building Departments had offered some emphatic suggestions to him concerning experiments of this nature.\",\"~Tesla\\'s observations in this experiment were limited to what took place on the floor of the building in which his laboratory was located, but apparently very little happened there until a great deal had happened elsewhere. The oscillator was firmly fixed to a supporting column and there were similar supporting columns directly under it on each floor down to the foundations. The vibrations were transmitted through the columns to the ground. This section of the city is built on deep sand that extends down some hundreds of feet before bed rock is reached. It is well known to seismologists that earthquake vibrations are transmitted by sand with much greater intensity than they are by rock. The ground under the building and around it was therefore, and excellent transmitter of mechanical vibrations, which spread out in all directions. They may have reached a mile or more. They were more intense, of course, near their source and became weaker as the distance increased. However, even\",\"\",\"weak vibrations that are sustained can build up surprisingly large effects when they are absorbed by an object with which they are in resonance.\",\"A distant object in resonance can be thrown into strong vibration whereas\",\"a much nearer object not in resonance will be left unaffected.\",\"It was this selective resonance that was, apparently, operating in Tesla\\'s experiment. Buildings other than his own came into resonance with the increasing tempo of his oscillator long before his own building was affected. After the pandemonium was under way for some time elsewhere and the higher frequencies were reached, his immediate surroundings started to come into resonance.\",\"When resonance is reached the effects follow instantly and powerfully. Tesla knew this, so when he observed dangerous resonance effects developing in his building he realized he had to act fast. The oscillator was being operated by compressed air supplied by a motor-driven compressor that fed the air into a tank, where it was stored under pressure.', mimetype='text/plain', start_char_idx=185413, end_char_idx=190187, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8208924589109055)], metadata={'757983b3-0b15-4da6-a916-d067e025ffb1': {'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, '199e5af0-39cc-46d2-b1fe-0094ca795e54': {'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, '58f773d7-512f-4244-ba01-8b95ca2f08f2': {'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}}), is_error=False)], source_nodes=[NodeWithScore(node=TextNode(id_='757983b3-0b15-4da6-a916-d067e025ffb1', embedding=None, metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='07422d86-a33f-4beb-b46a-d15ec9d29bc2', node_type='4', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='350f6898d24bbe393c5f1a8aec4d7c32a411e69f3093573b9f300d9874fa41fe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20406a92-0af9-4a53-8571-b182ffa7ffed', node_type='1', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='66ad6fbd0a0bfc5f107428036c18b47c1fc135dc6573c45fc919616e797cd084'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d240b337-6f22-4ab6-b161-4d4c4fe42869', node_type='1', metadata={}, hash='bb2bfef0fdb1f32a1efc7da29ed93249c05c7311f4c4d76adaaf85019b71f5f8')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\",\"His system of telegeodynamics, using mechanical vibrations, Tesla declared, would make it possible to determine the physical constant of the\",\"\",\"Earth and to locate ore deposits far beneath the surface. This latter prediction has since been fulfilled, for\",\"many oil fields have been discovered by studying the vibrations reflected from sub-surface strata.\",\"\\\\\"So powerful are the effects of the telegeodynamic oscillator,\\\\\" said Tesla in reviewing the subject in the thirties, \\\\\"that I could now go over to the Empire State Building and reduce it to a tangled mass of wreckage in a very short time. I could accomplish this result with utmost certainty and without any difficulty whatever. I would use a small mechanical vibrating device, an engine so small you could slip it in your pocket. I could attach it to any part of the building, start it in operation, allow it twelve to thirteen minutes to come to full resonance. The building would first respond with gentle tremors, and the vibrations would then become so powerful that the whole structure would go into resonant oscillations of such great amplitude and power that rivets in the steel beams would be loosened and sheared. The other stone coating would be thrown off and then the skeleton steel structure would collapse in all its parts. It would take about 2.5 * horsepower to drive the oscillator to produce this effect.\\\\\"\",\"This figure may have been .25 horsepower.\",\"The notes are old and somewhat indistinct. Memory favors the latter figure.\",\"Tesla developed his inventions to the point at which they were spectacular performers before they were demonstrated to the public.\",\"When presented, the performance always greatly exceeded the promise. This was the case with his first public demonstration of \\\\\"wireless,\\\\\" but he complicated the situation by coupling with his radio invention another new idea... the robot.\",\"\",\"Tesla was patriotic, and was proud of his status, which he had acquired in 1889, as a citizen of the United States. He had offered his invention to the Government as a naval weapon, but at heart he was opposed to war.\",\"\\\\\"You do not see there a wireless torpedo,\\\\\"snapped back Tesla with fire flashing in his eyes, \\\\\"you see there the first of a race of robots, mechanical men which will do the laborious work of the human race.\\\\\"\",\"The \\\\\"race of robots\\\\\" was another of Tesla\\'s original and important contributions to human welfare. It was one of the items of his colossal project for increasing human energy and improving the efficiency of its utilization. He visualized the application of the robot idea to warfare as well as to peaceful pursuits; and out of the broad principles enunciated, he developed and accurate picture of warfare as it is being carried on today with the use of giant machines as weapons... the robots he described.', mimetype='text/plain', start_char_idx=193246, end_char_idx=196081, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8364177457900843), NodeWithScore(node=TextNode(id_='199e5af0-39cc-46d2-b1fe-0094ca795e54', embedding=None, metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='07422d86-a33f-4beb-b46a-d15ec9d29bc2', node_type='4', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='350f6898d24bbe393c5f1a8aec4d7c32a411e69f3093573b9f300d9874fa41fe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f29cc8ea-66a3-4f1e-ad12-8dd937b24466', node_type='1', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='7f4ddebc3c006be13184de666ecea5c96d67d408ac2f27e7c9811bf5a7ba791d'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='90f9b9a3-3c65-4f8b-9fa4-2d42db76f8ec', node_type='1', metadata={}, hash='67c534fb0d91627bb021a3dee17f603055084cf979e3202213ea5500ab128d20')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Even when he did not so plan events, they appeared to fashion themselves into spectacular climaxes. In 1896 while his fame was still on the ascendant he planned a nice quiet little vibration experiment in his Houston Street laboratory. Since he had moved into these quarters in 1895, the place had established a reputation for itself because of the peculiar noises and lights that emanated from it at all hours of the day and night, and because it was constantly being visited by the most famous people in the country.\",\"The quiet little vibration experiment produced an earthquake, a real earthquake in which people and buildings and everything in them got a more tremendous shaking than they did in any of the natural earthquakes that have visited the metropolis. In an area of a dozen square city blocks, occupied by hundreds of buildings housing tens of thousands of persons, there was a sudden roaring and shaking, shattering of panes of glass, breaking of steam, gas and water pipes. Pandemonium reigned as small objects danced around rooms, plaster descended from walls and ceilings, and pieces of machinery weighing tons were moved from their bolted anchorages and shifted to awkward spots in factory lofts.\",\"\",\"Sounds like New York City\\'s biggest earthquake.\",\"\",\"\\\\\"It was all caused, quite unexpectedly, by a little piece of apparatus you could slip in your pocket,\\\\\" said Tesla.\",\"The device that precipitated the sudden crisis had been used for a long time by Tesla as a toy to amuse his friends. It was a mechanical oscillator, and was used to produce vibrations. The motor-driven device that the barber straps on his hand to give a patron an \\\\\"electric massage\\\\\" is a descendant of Tesla\\'s mechanical oscillator. There is, of course, nothing electric about an \\\\\"electric massage\\\\\" except the power used to produce vibrations which are transmitted through the barber\\'s fingers to the scalp.\",\"Tesla developed in the early nineties a mechanical-electrical oscillator for the generation of high-frequency alternating currents. The driving engine produced on a shaft simple reciprocating motion that was not changed to rotary motion. Mounted on either end of the shaft was a coil of many turns of wire that moved back and forth with high frequency between the poles of electromagnets, and in this way generated high-frequency alternating currents.\",\"The engine was claimed by Tesla to have a very high efficiency compared to the common type of engine, which changed reciprocating to rotary motion by means of a crank shaft. It had no valves or other moving parts, except the reciprocating piston with its attached shaft and coils, so that mechanical losses were very low. It maintained such an extremely high order of constancy of speed, he stated, that the alternating current generated by the oscillator could be used to drive clocks, without and pendulum or balance-wheel control mechanism, and they would keep time more accurately than the Sun.\",\"This engine may have had industrial possibilities but Tesla was not interested in them. To him it was just a convenient way of producing a high-frequency alternating current constant in frequency and voltage, or mechanical vibrations, it used without the electrical parts. He operated the engine on compressed air and also by steam at 320 pounds and also at 80 pounds pressure.\",\"Page 156Author was well informed...\",\"\",\"\",\"It was a mechanical oscillator\",\"While perfecting this devise, he had opportunity to observe interesting effects produced by vibration. These were objectionable in the engine when it was used as a dynamo, so he adopted suitable measures to eliminate or suppress them. The vibrations as such, however, interested him. Although they were detrimental to the machine, he found their physiological effects were, at times, quite pleasant. Later he built a small mechanical oscillator driven by compressed air which was designed for no other purpose than to produce vibrations. He built a platform insulated from the floor by rubber and cork. He then mounted the oscillator on the under side of the platform. The purpose of the rubber cork under the platform was to keep the vibrations from leaking into the building and thereby reducing the effect on the platform. Visitors found this vibrating platform one of the most interesting of the great array of fascinating and fantastic exhibits with which he dazzled the society folk who flocked to his laboratory.\",\"Great hopes were entertained by Tesla of applying these vibrations for therapeutic and health-improving effects. He had opportunity to observe, through his own experience and that of his employees, that they produced some very definite physiological actions.\",\"Samuel Clemens, better known to the public as \\\\\"Mark Twain\\\\\", and Tesla were close friends. Clemens was a frequent visitor to the Tesla laboratory. Tesla had been playing with his vibratory mechanism for some time, and had learned a good deal about the results that followed from varying doses of vibration, when one evening Clemens dropped in.\",\"Clemens, on learning about the new mechanism, wanted to experience its vitalizing vibrations.', mimetype='text/plain', start_char_idx=173309, end_char_idx=178451, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8239940410684508), NodeWithScore(node=TextNode(id_='58f773d7-512f-4244-ba01-8b95ca2f08f2', embedding=None, metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='07422d86-a33f-4beb-b46a-d15ec9d29bc2', node_type='4', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='350f6898d24bbe393c5f1a8aec4d7c32a411e69f3093573b9f300d9874fa41fe'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1ff2866f-ccf4-4990-a069-893659344147', node_type='1', metadata={'file_path': 'data/1k/web.txt', 'file_name': 'web.txt', 'file_type': 'text/plain', 'file_size': 210125, 'creation_date': '2025-09-05', 'last_modified_date': '2025-09-05'}, hash='4ddcc501cf0a83e7d3f3b2a4922efa4fd466472ac143f29e8a7d86cf9ca24ab7'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='20406a92-0af9-4a53-8571-b182ffa7ffed', node_type='1', metadata={}, hash='81df36ffcf4635f648faaf93d136808ce4a871b0d42e9fc539a40509aac63994')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\",\"Could they reach Tesla\\'s laboratory in time to stop him? Or would the building tumble down on their heads and everyone in it be buried in the ruins, and probably every building in the neighborhood? Maybe he was making the whole Earth shake in this way! Would this madman be destroying the world? It was destroyed once before by water. Maybe this time it would be destroyed by that agent of the devil that they call electricity!\",\"Just as the cops rushed into Tesla\\'s laboratory to tackle... they knew not what... the vibrations stopped and they beheld a strange sight. They arrived just in time to see the tall gaunt figure of the inventor swing a heavy sledge hammer and shatter a small iron contraption mounted on the post in the middle of the room. Pandemonium gave way to a deep, heavy silence.\",\"Tesla was the first to break the silence. Resting his sledge hammer against the pillar, he turned his tall, lean, coatless figure to the cops. He was always self-possessed, always a commanding presence... an effect that could in no way be attributed to his slender build, but seemed more to emanate from his eyes. Bowing from the waist in his courtly manner, he addressed the policemen, who were too out of breath to speak, and probably overawed into silence by their fantastic experience.\",\"\\\\\"Gentleman,\\\\\" he said, \\\\\"I am sorry, but you are just a trifle too late to witness my experiment. I found it necessary to stop it suddenly and unexpectedly and in and unusual way just as you entered. If you will come around this evening I will have another oscillator attached to this platform and\",\"\",\"each of you can stand on it. You will, I am sure, find it a most interesting and pleasurable experience. Now you must leave, for I have many things to do. Good day gentlemen.\\\\\"\",\"George Scherff, Tesla\\'s secretary, was standing near by when Tesla was so dramatically smashed his earthquake maker. Tesla never told the story beyond this point, and Mr. Scherff declares he does not recall what the response of the cops was. Imagination must furnish the finale to the story.\",\"At the moment, though, Tesla was quite sincere in his attitude. He had no idea of what had happened elsewhere in the neighborhood as a result of his experiment, but the effect on his own laboratory had been sufficiently threatening to cause him to halt is suddenly. When he learned the details, however, he was convinced that he was correct in his belief that the field of mechanical vibrations was rich with opportunities for scientific investigation. We have no records available of any further major experiments with vibration in that laboratory. Perhaps the Police and Building Departments had offered some emphatic suggestions to him concerning experiments of this nature.\",\"~Tesla\\'s observations in this experiment were limited to what took place on the floor of the building in which his laboratory was located, but apparently very little happened there until a great deal had happened elsewhere. The oscillator was firmly fixed to a supporting column and there were similar supporting columns directly under it on each floor down to the foundations. The vibrations were transmitted through the columns to the ground. This section of the city is built on deep sand that extends down some hundreds of feet before bed rock is reached. It is well known to seismologists that earthquake vibrations are transmitted by sand with much greater intensity than they are by rock. The ground under the building and around it was therefore, and excellent transmitter of mechanical vibrations, which spread out in all directions. They may have reached a mile or more. They were more intense, of course, near their source and became weaker as the distance increased. However, even\",\"\",\"weak vibrations that are sustained can build up surprisingly large effects when they are absorbed by an object with which they are in resonance.\",\"A distant object in resonance can be thrown into strong vibration whereas\",\"a much nearer object not in resonance will be left unaffected.\",\"It was this selective resonance that was, apparently, operating in Tesla\\'s experiment. Buildings other than his own came into resonance with the increasing tempo of his oscillator long before his own building was affected. After the pandemonium was under way for some time elsewhere and the higher frequencies were reached, his immediate surroundings started to come into resonance.\",\"When resonance is reached the effects follow instantly and powerfully. Tesla knew this, so when he observed dangerous resonance effects developing in his building he realized he had to act fast. The oscillator was being operated by compressed air supplied by a motor-driven compressor that fed the air into a tank, where it was stored under pressure.', mimetype='text/plain', start_char_idx=185413, end_char_idx=190187, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8208924589109055)], is_dummy_stream=False, metadata=None)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# agent.chat_repl()\n",
        "response = agent.chat(\"What influenced Nikola Tesla to become an inventor?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGakE3sO1F_5"
      },
      "source": [
        "# Agents with Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xwTwYSSjRihM"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply, name=\"multiply\")\n",
        "add_tool = FunctionTool.from_defaults(fn=add, name=\"add\")\n",
        "\n",
        "all_tools = [multiply_tool, add_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gRNaPGDyRieS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:08,007 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.objects import ObjectIndex, SimpleToolNodeMapping\n",
        "\n",
        "\n",
        "tool_mapping = SimpleToolNodeMapping.from_objects(all_tools)\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    all_tools,\n",
        "    tool_mapping,\n",
        "    VectorStoreIndex,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GNHxglUDKJ5L"
      },
      "outputs": [],
      "source": [
        "from llama_index.agent.openai_legacy import FnRetrieverOpenAIAgent\n",
        "\n",
        "\n",
        "agent = FnRetrieverOpenAIAgent.from_retriever(\n",
        "    obj_index.as_retriever(), verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSCd47OB2ZIN",
        "outputId": "665317f3-6710-4a72-f940-96fd50800ef0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:22,906 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTING TURN 1\n",
            "---------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:23,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: multiply with args: {\"a\": 12, \"b\": 22}\n",
            "Got output: 264\n",
            "========================\n",
            "\n",
            "STARTING TURN 2\n",
            "---------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:25,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AgentChatResponse(response='The result of multiplying 12 by 22 is 264.', sources=[ToolOutput(blocks=[TextBlock(block_type='text', text='264')], tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 12, 'b': 22}}, raw_output=264, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.chat(\"What's 12 multiplied by 22? Make sure to use Tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btL4lvUy2ZBK",
        "outputId": "6b36a503-321e-489f-8101-e20890367ddb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:45,783 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTING TURN 1\n",
            "---------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:46,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Calling Function ===\n",
            "Calling function: add with args: {\"a\":5,\"b\":2}\n",
            "Got output: 7\n",
            "========================\n",
            "\n",
            "STARTING TURN 2\n",
            "---------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-05 16:35:48,497 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AgentChatResponse(response='The result of adding 5 and 2 is 7.', sources=[ToolOutput(blocks=[TextBlock(block_type='text', text='7')], tool_name='add', raw_input={'args': (), 'kwargs': {'a': 5, 'b': 2}}, raw_output=7, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.chat(\"What is 5 + 2?\", tool_choice=\"add\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHfXq66zEZ7B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

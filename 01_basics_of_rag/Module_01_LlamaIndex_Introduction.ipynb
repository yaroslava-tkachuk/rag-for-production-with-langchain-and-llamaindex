{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gRt2BXzwASv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q llama-index deeplake openai cohere llama-index-readers-wikipedia wikipedia llama-index-vector-stores-deeplake python-dotenv setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "--Q2zk06wElp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv(\"../.env\")\n",
        "assert os.getenv(\"OPENAI_API_KEY\")\n",
        "assert os.getenv(\"ACTIVELOOP_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tjwZjA8-wITr"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "\n",
        "#You can set the logging level to DEBUG for more verbose output,\n",
        "# or use level=logging.INFO for less detailed information.\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLUDcXpI41Q_"
      },
      "source": [
        "# LlamaHub Wikipedia Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhaDzVaxwIRD",
        "outputId": "fc9cb5c0-c1b3-4641-c37c-77a93ff5eba9"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "\n",
        "loader = WikipediaReader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z35ot7P1wIO0"
      },
      "outputs": [],
      "source": [
        "documents = loader.load_data(pages=['Artificial_intelligence', 'Large_language_model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i9Zp6BJwILk",
        "outputId": "f7ade60f-631a-4b51-981a-26fda4f7c4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Doc ID: 1164\n",
            "Text: Artificial intelligence (AI) is the capability of computational\n",
            "systems to perform tasks typically associated with human intelligence,\n",
            "such as learning, reasoning, problem-solving, perception, and\n",
            "decision-making. It is a field of research in computer science that\n",
            "develops and studies methods and software that enable machines to\n",
            "perceive their e...\n"
          ]
        }
      ],
      "source": [
        "len(documents)\n",
        "print(documents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkKPAnIl44ss"
      },
      "source": [
        "# Create Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "\n",
        "\n",
        "# Assuming documents have already been loaded\n",
        "\n",
        "# Initialize the parser\n",
        "parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=20)\n",
        "\n",
        "# Parse documents into nodes\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "print(len(nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TextNode(id_='1f09ceaa-f84e-4e37-b7da-b2e08a3788f5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1164', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='180eac2a355b2a059172cb25f58793a3cb2f48e30029391defa1ac4230b622b9'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='fd63b318-1c5c-4374-91be-cef502943c72', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f9601e18e360cfa9304487a5cf3c79a5fb4876e92ef6fa45d81dc312c21a769c')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Artificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields. Some companies, such as OpenAI, Google DeepMind and Meta, aim to create artificial general intelligence (AGI)â€”AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture. In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI\\'s ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.', mimetype='text/plain', start_char_idx=0, end_char_idx=2799, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nodes[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03lff4VUTaN9"
      },
      "source": [
        "# Save on DeepLake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo8CTHSFTcaR",
        "outputId": "adbf0c99-61ec-4879-eede-15d7cd7e8d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:deeplake.storage.s3:[S3] Failed to get bucket region for URL: snark-hub/protected/yaroslava/LlamaIndex_intro/ with error: [S3] INVALID_ACCESS_KEY_ID snark-hub The AWS Access Key Id you provided does not exist in our records. \n",
            "[S3] Failed to get bucket region for URL: snark-hub/protected/yaroslava/LlamaIndex_intro/ with error: [S3] INVALID_ACCESS_KEY_ID snark-hub The AWS Access Key Id you provided does not exist in our records. \n"
          ]
        }
      ],
      "source": [
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "\n",
        "\n",
        "my_activeloop_org_id = \"yaroslava\"\n",
        "my_activeloop_dataset_name = \"LlamaIndex_intro\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "# Create an index over the documents\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eWFtVpM_TcTQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import StorageContext\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'LLM stands for Language Learning Model.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What does LLM stand for?\")\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCgdd197CTDt"
      },
      "source": [
        "# Create local index from Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G7BdNn-Q5AlG",
        "outputId": "2f78963e-830e-45bd-c6f8-50a99be55cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Natural Language Processing'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index.core import GPTVectorStoreIndex\n",
        "\n",
        "\n",
        "# Using a temporary local index\n",
        "local_index = GPTVectorStoreIndex.from_documents(documents)\n",
        "query_engine = local_index.as_query_engine()\n",
        "response = query_engine.query(\"What does NLP stand for?\")\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGKUVg3wI0d"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKHDHMsIwIGp",
        "outputId": "4865ddd8-6d81-4f17-c1b0-a877065d2ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                                 Version\n",
            "--------------------------------------- ---------------\n",
            "aiohappyeyeballs                        2.6.1\n",
            "aiohttp                                 3.12.15\n",
            "aiosignal                               1.4.0\n",
            "aiosqlite                               0.21.0\n",
            "annotated-types                         0.7.0\n",
            "anyio                                   4.10.0\n",
            "appnope                                 0.1.4\n",
            "asttokens                               3.0.0\n",
            "attrs                                   25.3.0\n",
            "banks                                   2.2.0\n",
            "beautifulsoup4                          4.13.5\n",
            "certifi                                 2025.8.3\n",
            "charset-normalizer                      3.4.3\n",
            "click                                   8.2.1\n",
            "cohere                                  5.17.0\n",
            "colorama                                0.4.6\n",
            "comm                                    0.2.3\n",
            "dataclasses-json                        0.6.7\n",
            "debugpy                                 1.8.16\n",
            "decorator                               5.2.1\n",
            "deepframe                               0.1.0\n",
            "deeplake                                4.3.1\n",
            "defusedxml                              0.7.1\n",
            "Deprecated                              1.2.18\n",
            "dirtyjson                               1.0.8\n",
            "distro                                  1.9.0\n",
            "executing                               2.2.1\n",
            "fastavro                                1.12.0\n",
            "filelock                                3.19.1\n",
            "filetype                                1.2.0\n",
            "frozenlist                              1.7.0\n",
            "fsspec                                  2025.9.0\n",
            "greenlet                                3.2.4\n",
            "griffe                                  1.13.0\n",
            "h11                                     0.16.0\n",
            "hf-xet                                  1.1.9\n",
            "httpcore                                1.0.9\n",
            "httpx                                   0.28.1\n",
            "httpx-sse                               0.4.0\n",
            "huggingface-hub                         0.34.4\n",
            "idna                                    3.10\n",
            "ipykernel                               6.30.1\n",
            "ipython                                 9.5.0\n",
            "ipython_pygments_lexers                 1.1.1\n",
            "jedi                                    0.19.2\n",
            "Jinja2                                  3.1.6\n",
            "jiter                                   0.10.0\n",
            "joblib                                  1.5.2\n",
            "jupyter_client                          8.6.3\n",
            "jupyter_core                            5.8.1\n",
            "llama-cloud                             0.1.35\n",
            "llama-cloud-services                    0.6.54\n",
            "llama-index                             0.13.4\n",
            "llama-index-cli                         0.5.0\n",
            "llama-index-core                        0.13.4\n",
            "llama-index-embeddings-openai           0.5.0\n",
            "llama-index-indices-managed-llama-cloud 0.9.3\n",
            "llama-index-instrumentation             0.4.0\n",
            "llama-index-llms-openai                 0.5.4\n",
            "llama-index-readers-file                0.5.2\n",
            "llama-index-readers-llama-parse         0.5.0\n",
            "llama-index-readers-wikipedia           0.4.0\n",
            "llama-index-vector-stores-deeplake      0.4.0\n",
            "llama-index-workflows                   1.3.0\n",
            "llama-parse                             0.6.54\n",
            "MarkupSafe                              3.0.2\n",
            "marshmallow                             3.26.1\n",
            "matplotlib-inline                       0.1.7\n",
            "multidict                               6.6.4\n",
            "mypy_extensions                         1.1.0\n",
            "nest-asyncio                            1.6.0\n",
            "networkx                                3.5\n",
            "nltk                                    3.9.1\n",
            "numpy                                   1.26.4\n",
            "openai                                  1.104.2\n",
            "packaging                               25.0\n",
            "pandas                                  2.2.3\n",
            "parso                                   0.8.5\n",
            "pexpect                                 4.9.0\n",
            "pillow                                  11.3.0\n",
            "pip                                     24.0\n",
            "platformdirs                            4.4.0\n",
            "prompt_toolkit                          3.0.52\n",
            "propcache                               0.3.2\n",
            "psutil                                  7.0.0\n",
            "ptyprocess                              0.7.0\n",
            "pure_eval                               0.2.3\n",
            "pydantic                                2.11.7\n",
            "pydantic_core                           2.33.2\n",
            "Pygments                                2.19.2\n",
            "PyJWT                                   2.10.1\n",
            "pypdf                                   6.0.0\n",
            "python-dateutil                         2.9.0.post0\n",
            "python-dotenv                           1.1.1\n",
            "pytz                                    2025.2\n",
            "PyYAML                                  6.0.2\n",
            "pyzmq                                   27.0.2\n",
            "regex                                   2025.9.1\n",
            "requests                                2.32.5\n",
            "setuptools                              80.9.0\n",
            "six                                     1.17.0\n",
            "sniffio                                 1.3.1\n",
            "soupsieve                               2.8\n",
            "SQLAlchemy                              2.0.43\n",
            "stack-data                              0.6.3\n",
            "striprtf                                0.0.26\n",
            "tenacity                                9.1.2\n",
            "tiktoken                                0.11.0\n",
            "tokenizers                              0.22.0\n",
            "tornado                                 6.5.2\n",
            "tqdm                                    4.67.1\n",
            "traitlets                               5.14.3\n",
            "types-requests                          2.32.4.20250809\n",
            "typing_extensions                       4.15.0\n",
            "typing-inspect                          0.9.0\n",
            "typing-inspection                       0.4.1\n",
            "tzdata                                  2025.2\n",
            "urllib3                                 2.5.0\n",
            "wcwidth                                 0.2.13\n",
            "wikipedia                               1.4.0\n",
            "wrapt                                   1.17.3\n",
            "yarl                                    1.20.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mtGKUVg3wI0d"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
